{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anshumansengar/Automation-scripts/blob/main/accident_classification2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wwdhy81q5e5A"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import glob\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd \n",
        "from tensorflow.keras import layers\n",
        "from time import perf_counter \n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "7V56nN5aaLEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "metadata": {
        "id": "aLQFcJFt5omM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir=\"/content/drive/MyDrive/acc/data/train\"\n",
        "val_dir=\"/content/drive/MyDrive/acc/data/val\""
      ],
      "metadata": {
        "id": "GZvn-NRbA9kD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ['accident','car']"
      ],
      "metadata": {
        "id": "vJWW1S2i9sx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE =100\n",
        "IMG_SHAPE = 150\n",
        "image_gen_train = ImageDataGenerator(rescale =1./255,horizontal_flip=True,zoom_range=0.5,rotation_range=45)\n",
        "\n",
        "\n",
        "train_data_gen = image_gen_train.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                                     directory=train_dir,\n",
        "                                                     shuffle=True,\n",
        "                                                     target_size=(IMG_SHAPE,IMG_SHAPE),\n",
        "                                                     class_mode='sparse')\n",
        "image_gen_val = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "val_data_gen = image_gen_val.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                                 directory=val_dir,\n",
        "                                                  target_size=(IMG_SHAPE,IMG_SHAPE),\n",
        "                                                  class_mode='sparse')\n",
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
        "plotImages(augmented_images)\n"
      ],
      "metadata": {
        "id": "9WIvm5iB5oyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "       tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_SHAPE,IMG_SHAPE, 3)),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2), \n",
        "         tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2), \n",
        "         tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),  \n",
        "        tf.keras.layers.Flatten(),\n",
        "         tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "     tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation=\"softmax\")                         \n",
        "])\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "               metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "j_PlKd0o-IhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 30\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=int(np.ceil(train_data_gen.n / float(BATCH_SIZE))),\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=int(np.ceil(val_data_gen.n / float(BATCH_SIZE)))\n",
        ")"
      ],
      "metadata": {
        "id": "gQuPNivT-MZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Kgj-Z1m--QzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/drive/MyDrive/acc/final_model.h5\")\n"
      ],
      "metadata": {
        "id": "ZMHBHESWTii2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/drive/MyDrive/acc\"\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import imutils\n",
        "from PIL import Image\n",
        "import time\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "COLORS = [(0, 240, 0), (255,0, 0)]\n",
        "\n",
        "model = tf.keras.models.load_model(\"final_model.h5\")\n",
        "model.build()\n",
        "classe=[\"Everything good\",\"ACCIDENT !\"]\n",
        "\n",
        "cap = cv2.VideoCapture('1.mp4')\n",
        "frame_width = int(cap.get(3))\n",
        "\n",
        "frame_height = int(cap.get(4))\n",
        "\n",
        "\n",
        "\n",
        "dim = (150,150)\n",
        "out = cv2.VideoWriter('output3.mp4',cv2.VideoWriter_fourcc('M','J','P','G'), 10, (frame_width,frame_height))\n",
        "starting_time = time.time()\n",
        "frame_counter = 0\n",
        "org = (10, 50)\n",
        "font = cv2.FONT_HERSHEY_PLAIN\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    frame_counter += 1\n",
        "    if ret == False:\n",
        "        break\n",
        " \n",
        "    \n",
        "    x=frame\n",
        "    x = cv2.resize(x, dim, interpolation=cv2.INTER_AREA)\n",
        "    \n",
        "\n",
        "  \n",
        "    \n",
        " \n",
        "    x =np.array(x)\n",
        "    x=x.astype(np.float)\n",
        "    x/=255.0\n",
        "    pred_frame=np.expand_dims(x,axis=0)\n",
        "    label=model.predict(pred_frame)\n",
        "    print(label[0])\n",
        "    \n",
        "    if(label[0][0]<0.45):\n",
        "      A=0\n",
        "    else:\n",
        "      A=1\n",
        "    cv2.putText(frame, classe[A], org, font,  1, COLORS[A], 1, cv2.LINE_AA)\n",
        "                  \n",
        " \n",
        " \n",
        "    out.write(frame)\n",
        "    key = cv2.waitKey(0)\n",
        "    \n",
        "    \n",
        "   \n",
        "    if key == ord('q'):\n",
        "        break\n",
        "out.release()\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "print('done')"
      ],
      "metadata": {
        "id": "vnjOyiYF7S3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/drive/MyDrive/acc\"\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import imutils\n",
        "from PIL import Image\n",
        "import time\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "COLORS = [(150, 150, 0), (0, 150, 150)]\n",
        "\n",
        "model = tf.keras.models.load_model(\"final_model.h5\")\n",
        "model.build()\n",
        "classe=[\"ACCIDENT !\",\"Everything good\"]\n",
        "\n",
        "cap = cv2.VideoCapture('1.mp4')\n",
        "frame_width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
        "frame_height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
        "\n",
        "\n",
        "dim = (150,150)\n",
        "    out = cv2.VideoWriter('outpy.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 10, (frame_width,frame_height))\n",
        " \n",
        "starting_time = time.time()\n",
        "frame_counter = 0\n",
        "org = (10, 50)\n",
        "font = cv2.FONT_HERSHEY_PLAIN\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    frame_counter += 1\n",
        "    if ret == False:\n",
        "        break\n",
        "\n",
        "    \n",
        "    \n",
        "    frame= cv2.resize(frame, dim, interpolation=cv2.INTER_AREA)\n",
        "    \n",
        "\n",
        "  \n",
        "    \n",
        "    out.write(frame)\n",
        "\n",
        "    frame =np.array(frame)\n",
        "    frame=frame.astype(np.float)\n",
        "    frame/=255.0\n",
        "    pred_frame=np.expand_dims(frame,axis=0)\n",
        "    label=model.predict(pred_frame)\n",
        "    print(label[0])\n",
        "    print(label[0])\n",
        "    if(label[0][0]>0.3):\n",
        "      A=0\n",
        "    else:\n",
        "      A=1\n",
        "    cv2.putText(frame, classe[A], org, font,  1, COLORS[A], 1, cv2.LINE_AA)\n",
        "                  \n",
        "\n",
        "\n",
        "   \n",
        "    \n",
        "    \n",
        "    if key == ord('q'):\n",
        "        break\n",
        "out.release()\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "print('done')"
      ],
      "metadata": {
        "id": "6RF_JTrzXYWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ianI9rFG3jWi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}